{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameter cell\n",
    "DEVICES = \"1,2\"\n",
    "FROM = \"2019-01-01\"\n",
    "TO = \"2020-01-01\"\n",
    "COUNTRY = \"Vietnam\"\n",
    "ORDER = 1  # will be pass to param order in biLouvian call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICES\n",
    "\n",
    "import re\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cudf\n",
    "import networkx as nx\n",
    "from cuml.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data and filter by the Paramteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cudf.read_parquet(\"../fulldata/kiva_activity_2023-08-28T11-09-39.parquet\")\n",
    "ds[\"sector_name\"] = ds[\"sector_name\"].astype(\"category\")\n",
    "ds[\"geocode_country_name\"] = ds[\"geocode_country_name\"].astype(\"category\")\n",
    "ds[\"activity_name\"] = ds[\"activity_name\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dropna(axis=0, how=\"all\", inplace=True)\n",
    "print(len(ds))\n",
    "ds.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COUNTRY.lower() != \"all\":\n",
    "    ds = ds[ds[\"geocode_country_name\"] == COUNTRY]\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to limit the timeline, because I am not yet comfortable to work with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[(ds.fundraisingDate >= FROM) & (ds.fundraisingDate < TO)]\n",
    "\"the number of Loans (might duplicated) under investigation is\", len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.rename(columns={\"id\": \"project_id\", \"name\": \"project_name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicated Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are Projects which have a same `project_id` but different `fundedAmount`\n",
    "It might because the query time is different\n",
    "Here, only keep records which have the highest `fundedAmount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds.groupby(\"project_id\", group_keys=False)[[\"loanFundraisingInfo_fundedAmount\"]].idxmax()\n",
    "iloc = temp[\"loanFundraisingInfo_fundedAmount\"].values  # NOTE: just iloc, not loc\n",
    "ds = ds.iloc[iloc]\n",
    "del iloc\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == len(ds[ds.duplicated(subset=[\"project_id\"], keep=False)].sort_values(by=[\"project_id\"]))  # no duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"the number of Projects (no duplicated) under investigation is\", len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `Lender-Project-Sector` df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ds.explode(\"lendingActions_values\")\n",
    "len(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some loans that has no lender\n",
    "ads.dropna(subset=[\"lendingActions_values\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict processing cant be done in cuDF, so convert to pandas\n",
    "adf = ads.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf[\"lender_id\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"lender\"][\"id\"], axis=1).astype(int)\n",
    "adf[\"lender_name\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"lender\"][\"name\"], axis=1)\n",
    "adf[\"lender_publicId\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"lender\"][\"publicId\"], axis=1)\n",
    "adf[\"loan_shareAmount\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"shareAmount\"], axis=1).astype(float)\n",
    "adf[\"loan_date\"] = pd.to_datetime(\n",
    "    adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"latestSharePurchaseDate\"], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuDF do not work with timezone yet\n",
    "adf[\"loan_date\"] = adf[\"loan_date\"].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.drop([\"lendingActions_values\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = cudf.from_pandas(adf)\n",
    "del adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == ads.duplicated(subset=[\"project_id\", \"lender_id\", \"loan_shareAmount\", \"loan_date\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads[\"loan_id\"] = cp.arange(len(ads[\"lender_id\"])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.duplicated().sum()  # NOTE: only work with small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.drop_duplicates(inplace=True)  # NOTE: only work with small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove anonymous Lenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"anynomous Lenders\")\n",
    "anons = ads.lender_publicId.str.startswith(\"anon\")\n",
    "ads[anons][[\"lender_id\", \"lender_name\", \"lender_publicId\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those anon\n",
    "ads = ads[~anons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Loans\", ads.project_id.unique().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Lenders\", ads.lender_id.unique().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct `Lender-Sector` bipartite graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edge list of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS = ads.groupby([\"lender_id\", \"lender_publicId\", \"sector_id\", \"sector_name\"]).agg(\n",
    "    {\"sector_name\": \"first\", \"loan_shareAmount\": \"sum\", \"loan_date\": \"count\"}\n",
    ")\n",
    "LS.reset_index(inplace=True)\n",
    "LS.rename(columns={\"loan_shareAmount\": \"loan_amount\", \"loan_date\": \"loan_count\"}, inplace=True)\n",
    "LS = LS[LS[\"loan_amount\"] > 0]\n",
    "LS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to the format that `biLouvian` can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "LS[\"V1\"] = le1.fit_transform(LS[\"sector_name\"])\n",
    "le2 = LabelEncoder()\n",
    "LS[\"V2\"] = le2.fit_transform(LS[\"lender_id\"]) + LS[\"V1\"].max() + 1\n",
    "LS.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of vertex\n",
    "vertex_count = LS[\"lender_id\"].nunique() + LS[\"sector_name\"].nunique()\n",
    "assert vertex_count == LS[\"V1\"].nunique() + LS[\"V2\"].nunique()\n",
    "print(vertex_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary1 = LS[[\"V1\", \"sector_name\"]].drop_duplicates()\n",
    "dictionary1.rename(columns={\"sector_name\": \"name\", \"V1\": \"id\"}, inplace=True)\n",
    "dictionary1[\"name\"] = dictionary1[\"name\"].astype(str)\n",
    "dictionary1.sort_values(by=[\"id\"]).tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary2 = LS[[\"V2\", \"lender_publicId\"]].drop_duplicates()\n",
    "dictionary2.rename(columns={\"lender_publicId\": \"name\", \"V2\": \"id\"}, inplace=True)\n",
    "dictionary2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat two dictionaries\n",
    "dictionary = cudf.concat([dictionary1, dictionary2])\n",
    "print(len(dictionary))\n",
    "assert len(dictionary) == vertex_count\n",
    "dictionary.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = f\"checkpoints/LS_bipartite_{COUNTRY}_from{FROM}_to{TO}_order{ORDER}\"  # the text \"bipartite\" is mandatory\n",
    "filename = f\"{prefix}.csv\"\n",
    "dictfile = f\"{prefix}_Dictionary.txt\"  # \"_Dictionary.txt\" is mandatory\n",
    "LS[[\"V1\", \"V2\", \"loan_amount\"]].to_csv(filename, sep=\"\\t\", header=False, index=False)  # \"\\t\" is mandatory\n",
    "dictionary[[\"id\", \"name\"]].to_csv(dictfile, sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run `biLouvian`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Have to build the `biLouvian` binary first. Refer to `doc/BUILD_BILOUVIAN.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../extra/biLouvian -i $filename -order $ORDER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
