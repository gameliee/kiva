{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = \"2,3\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cudf\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data\n",
    "First, read data in `.jsonl` file format as a pandas data frame\n",
    "Then store the dataframe in `.parquet` format for easy access later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "df = pd.read_json(\"../fulldata/kiva_activity_2023-08-28T11-09-39.jsonl\", lines=True)\n",
    "df = pd.json_normalize(df[\"loan\"], sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "df[\"loanAmount\"] = df[\"loanAmount\"].astype(float)\n",
    "df[\"loanFundraisingInfo_fundedAmount\"] = df[\"loanFundraisingInfo_fundedAmount\"].astype(float)\n",
    "df[\"raisedDate\"] = pd.to_datetime(df[\"raisedDate\"])\n",
    "df[\"fundraisingDate\"] = pd.to_datetime(df[\"fundraisingDate\"])\n",
    "df[\"geocode_country_name\"] = df[\"geocode_country_name\"].astype(\"category\")\n",
    "df[\"sector_id\"] = df[\"sector_id\"].astype(int)\n",
    "df[\"sector_name\"] = df[\"sector_name\"].astype(\"category\")\n",
    "df[\"activity_id\"] = df[\"activity_id\"].astype(int)\n",
    "df[\"activity_name\"] = df[\"activity_name\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "df.to_parquet(\"../fulldata/kiva_activity_2023-08-28T11-09-39.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cudf.read_parquet(\"../fulldata/kiva_activity_2023-08-28T11-09-39.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dropna(axis=0, how=\"all\", inplace=True)\n",
    "ds.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering, only take `Vietnam` into account\n",
    "Why? Because there are a lot of rows and we try to localize the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['geocode_country_name'].value_counts()['Vietnam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[ds['geocode_country_name'] == 'Vietnam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is construct a graph with following node type\n",
    "- `Lender`\n",
    "- `Loan`\n",
    "- `Tag`\n",
    "\n",
    "With following relationships\n",
    "- `Lender`s can `LEND` to `Loan`s\n",
    "- `Loan`s can be `TAGGED_WITH` `Tag`s\n",
    "\n",
    "Lenders have properties\n",
    "- `id`\n",
    "- `name`\n",
    "- `publicId`\n",
    "\n",
    "Loan have properties\n",
    "- `id`\n",
    "- `name`\n",
    "- `loanAmount`\n",
    "- `fundedAmount`\n",
    "- `postDate`\n",
    "- `raisedDate`\n",
    "\n",
    "`Tag` have properties:\n",
    "- `name`\n",
    "\n",
    "LEND's properties\n",
    "- `shareAmount`\n",
    "- `date`\n",
    "\n",
    "TAGGED_WITH have no properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicated `loan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are loans which have a same `id` but different `fundedAmount`\n",
    "It might because the query time is different\n",
    "Here, only keep records which have the highest `fundedAmount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.loc[[9628, 1366545]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds.groupby('id', group_keys=False)[['loanFundraisingInfo_fundedAmount']].idxmax()\n",
    "iloc = temp['loanFundraisingInfo_fundedAmount'].values # NOTE: just iloc, not loc\n",
    "ds = ds.iloc[iloc]\n",
    "del iloc\n",
    "del temp\n",
    "ds.loc[[9628, 1366545]] # see, only keep the one with higher fundedAmount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds.duplicated(subset=['id'], keep=False)].sort_values(by=['id']) # no duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `lender-loan-tag` df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ds.explode('tags').explode('lendingActions_values')\n",
    "del ds\n",
    "len(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads['tags'] = ads['tags'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some loans that has no lender\n",
    "ads.dropna(subset=['lendingActions_values'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict processing cant be done in cuDF, so convert to pandas\n",
    "adf = ads.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['lender_id'] = adf.progress_apply(lambda x: x['lendingActions_values']['lender']['id'], axis=1).astype(int)\n",
    "adf['lender_name'] = adf.progress_apply(lambda x: x['lendingActions_values']['lender']['name'], axis=1)\n",
    "adf['lender_publicId'] = adf.progress_apply(lambda x: x['lendingActions_values']['lender']['publicId'], axis=1)\n",
    "adf['shareAmount'] = adf.progress_apply(lambda x: x['lendingActions_values']['shareAmount'], axis=1).astype(float)\n",
    "adf['date'] = pd.to_datetime(adf.progress_apply(lambda x: x['lendingActions_values']['latestSharePurchaseDate'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuDF do not work with timezone yet\n",
    "adf['date'] = adf['date'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = cudf.from_pandas(adf)\n",
    "del adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.drop(['lendingActions_values'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.to_feather(\"ads.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = \"2,3\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cudf\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "ads = cudf.read_feather(\"ads.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove some tags \n",
    "The folowing tags should be remove:  \n",
    "- `tag_`\n",
    "- `user_favorite`\n",
    "- `user_like`\n",
    "- `volunteer_like`\n",
    "- `volunteer_pick`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'user_like' not in ads['tags'].cat.categories:\n",
    "    ads['tags'] = ads['tags'].cat.add_categories(['user_like'])\n",
    "\n",
    "if 'user_favorite' not in ads['tags'].cat.categories:\n",
    "    ads['tags'] = ads['tags'].cat.add_categories(['user_favorite'])\n",
    "\n",
    "if 'volunteer_like' not in ads['tags'].cat.categories:\n",
    "    ads['tags'] = ads['tags'].cat.add_categories(['volunteer_like'])\n",
    "\n",
    "if 'volunteer_pick' not in ads['tags'].cat.categories:\n",
    "    ads['tags'] = ads['tags'].cat.add_categories(['volunteer_pick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ads['tags'] == 'user_favorite').sum(), (ads['tags'] == 'user_like').sum(), (ads['tags'] == 'volunteer_like').sum(), (ads['tags'] == 'volunteer_pick').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ads[~ads['tags'].isin(['user_favorite', 'user_like', 'volunteer_like', 'volunteer_pick'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `Tag` nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create those df\n",
    "ds_tags = ads[['tags']].drop_duplicates().dropna()\n",
    "ds_tags[':LABEL'] = 'Tag'\n",
    "ds_tags.rename(columns={'tags': 'name:ID'}, inplace=True)\n",
    "ds_tags.to_csv('../data/neo4jtry/tags.csv',index=False)\n",
    "del ds_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `Loan` nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loan = ads.drop(['tags', 'lendingActions_totalCount', 'lender_id', 'lender_name', 'lender_publicId', 'shareAmount', 'date'], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loan[':LABEL'] = 'Loan'\n",
    "ds_loan.rename(columns={'id': 'id:ID(Loan-ID)'}, inplace=True)\n",
    "ds_loan.to_csv('../data/neo4jtry/loans.csv',index=False)\n",
    "del ds_loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `Lender` nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender = ads[['lender_id', 'lender_name', 'lender_publicId']].drop_duplicates()\n",
    "ds_lender.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender[ds_lender.duplicated(subset=['lender_id'], keep=False)].sort_values(by=['lender_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_lender_id = ds_lender[ds_lender.duplicated(subset=['lender_id'])]['lender_id']\n",
    "should_remove = ds_lender[(ds_lender['lender_id'].isin(duplicated_lender_id)) & (ds_lender['lender_publicId'].isna())]\n",
    "ds_lender.drop(should_remove.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated_lender who publicId is None\n",
    "duplicated_lender_id = ds_lender[ds_lender.duplicated(subset=['lender_id'])]['lender_id']\n",
    "should_remove = ds_lender[(ds_lender['lender_id'].isin(duplicated_lender_id)) & (ds_lender['lender_publicId'].isna())]\n",
    "ds_lender.drop(should_remove.index, axis=0, inplace=True)\n",
    "# still duplicate, might be because user change name and publicId. Just remove duplicates here.\n",
    "ds_lender.drop_duplicates(subset='lender_id', inplace=True)\n",
    "del duplicated_lender_id\n",
    "del should_remove\n",
    "# display the duplicated\n",
    "ds_lender[ds_lender.duplicated(subset=['lender_id'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender.rename(columns={'id': 'id:ID(Lender-ID)'}, inplace=True)\n",
    "ds_lender[':LABEL'] = 'Lender'\n",
    "ds_lender.to_csv('../data/neo4jtry/lenders.csv',index=False)\n",
    "del ds_lender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `TAGGED_WITH` relationship between `Loan` and `Tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loan_tags = ads[['id', 'tags']].dropna() # dropna helps to avoid inplace here, because we're process in a slide of the `ads`\n",
    "ds_loan_tags.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'the number of loans is ', len(ads[['id']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loan_tags.drop_duplicates(inplace=True)\n",
    "ds_loan_tags.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'the number of loan-tag relationships is', len(ds_loan_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loan_tags['tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loan_tags.rename(columns={'id': ':START_ID(Loan-ID)', 'tags': ':END_ID'}, inplace=True)\n",
    "ds_loan_tags[':TYPE'] = 'TAGGED_WITH'\n",
    "ds_loan_tags.to_csv('../data/neo4jtry/loan_tags.csv', index=False)\n",
    "del ds_loan_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `LEND` relationship between `Lender` and `Loan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan = ads[['id', 'lender_id', 'shareAmount', 'date']]\n",
    "ds_lender_loan.dropna(inplace=True)\n",
    "ds_lender_loan.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan.drop_duplicates(inplace=True) # duplicated cause by exploding the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan[':TYPE'] = 'LEND'\n",
    "ds_lender_loan.rename(columns={'lender_id': ':START_ID(Lender-ID)', 'id':':END_ID(Loan-ID)'}, inplace=True)\n",
    "ds_lender_loan.to_csv('../data/neo4jtry/lender_loan.csv', index=False)\n",
    "del ds_lender_loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually create the `SHARES_LOANS` relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan = ads[['id', 'lender_id', 'shareAmount', 'date']]\n",
    "ds_lender_loan.dropna(inplace=True)\n",
    "ds_lender_loan.drop_duplicates(inplace=True) # duplicated cause by exploding the tags\n",
    "ds_lender_loan.drop(['shareAmount', 'date'], axis=1, inplace=True)\n",
    "ds_lender_loan.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan.to_feather(\"ds_lender_loan.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan = cudf.read_feather(\"ds_lender_loan.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan.lender_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads[ads['tags'] == '#Married'].id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lender_loan.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"expected number of row of self_merge is\", pow(ds_lender_loan.lender_id.nunique()/ds_lender_loan.id.nunique(), 2) * ds_lender_loan.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_merged = ds_lender_loan.merge(ds_lender_loan, on='id')\n",
    "del ds_lender_loan\n",
    "self_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_merged = self_merged[self_merged['lender_id_x'] > self_merged['lender_id_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_loan = self_merged.groupby(['lender_id_x', 'lender_id_y']).nunique().reset_index()\n",
    "shares_loan.rename(columns={'id': \"number_common_loans\"}, inplace=True)\n",
    "del self_merged\n",
    "shares_loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shares_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_loan.rename(\n",
    "    columns={\n",
    "        'lender_id_x': ':START_ID(Lender-ID)', \n",
    "        'lender_id_y': ':END_ID(Lender-ID)',\n",
    "        'id': 'weight'\n",
    "        }, inplace=True)\n",
    "shares_loan[':TYPE'] = 'SHARES_LOAN'\n",
    "shares_loan.to_csv('../data/neo4jtry/lender_lender_share_loan.csv', index=False)\n",
    "del shares_loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually creat the `INTEREST` relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds = ads[['id', 'tags', 'lender_id', 'shareAmount', 'date']]\n",
    "lender_tag_ds.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds = lender_tag_ds.groupby(['lender_id', 'tags']).count()\n",
    "lender_tag_ds.reset_index(inplace=True)\n",
    "lender_tag_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.drop(['shareAmount', 'date'], axis=1, inplace=True)\n",
    "lender_tag_ds.rename(columns={'id': 'weight'}, inplace=True)\n",
    "lender_tag_ds.sort_values(by=['weight'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds[':TYPE'] = 'INTEREST'\n",
    "lender_tag_ds.rename(columns={'lender_id': ':START_ID(Lender-ID)', 'tags':':END_ID(Tag-ID)'})\\\n",
    "    .to_csv('../data/neo4jtry/lender_tag.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually create the `SHARE_TAGS` relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.drop(['weight', ':TYPE'], axis=1, inplace=True)\n",
    "lender_tag_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.memory_usage().sum() / pow(2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.memory_usage().sum() / pow(2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.to_csv('temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = \"1,2\"\n",
    "n_devices = len(DEVICES.split(','))\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cudf\n",
    "import dask_cudf\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "lender_tag_ds : cudf.DataFrame = cudf.read_csv('temp.csv')\n",
    "lender_tag_ds['lender_id'] = lender_tag_ds['lender_id'].astype('uint32')\n",
    "lender_tag_ds['tags'] = lender_tag_ds['tags'].astype('category')\n",
    "lender_tag_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding the tags, for easy integration with `parquet` and later programming. But, remember to store the label encoder\n",
    "from cuml.preprocessing.LabelEncoder import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "lender_tag_ds['tags'] = le.fit_transform(lender_tag_ds['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds = lender_tag_ds.sort_values(by=['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.lender_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.tags.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_row = pow(lender_tag_ds.lender_id.nunique()/lender_tag_ds.tags.nunique(), 2) * lender_tag_ds.tags.nunique()\n",
    "\"expected number of row of self_merged is\", exp_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///lender_tag.sqlite', echo=False)\n",
    "engine = create_engine('postgresql+psycopg2://postgres:postgres@localhost:32772/datdb', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lender_tag_ds.to_pandas().to_sql(name='lender_tag', con=engine, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Dask-cuDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "cluster = LocalCUDACluster(CUDA_VISIBLE_DEVICES=DEVICES, memory_limit=\"auto\", device_memory_limit=\"auto\", n_workers=None)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defined the computation graph, and execute it in background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lds = lender_tag_ds.set_index('tags')\n",
    "lds = lender_tag_ds\n",
    "ddf : dask_cudf.DataFrame = dask_cudf.from_cudf(lds, npartitions=1024) # here we use tags as index, so it would split into 32 partitions\n",
    "# ddf : dask_cudf.DataFrame = dask_cudf.from_cudf(lds, chunksize=1024)\n",
    "print(\"number of divisior\", len(ddf.divisions))\n",
    "\n",
    "merged : dask_cudf.DataFrame = ddf.merge(ddf, on='tags', npartitions=8192)\n",
    "print(\"number of divisior\", len(merged.divisions))\n",
    "# merged = merged.repartition(npartitions=8192)\n",
    "# print(\"number of divisior\", len(merged.divisions))\n",
    "\n",
    "filtered : dask_cudf.DataFrame = merged[merged['lender_id_x'] > merged['lender_id_y']]\n",
    "# filtered = filtered.repartition(npartitions=1024)\n",
    "# filtered = filtered.reset_index() # should avoid this\n",
    "print(\"number of divisior\", len(filtered.divisions))\n",
    "filtered = client.persist(filtered)\n",
    "\n",
    "\n",
    "def nunique(series):\n",
    "    return series.nunique()\n",
    "\n",
    "share_tags_ds_dask_collection : dask_cudf.DataFrame = filtered.groupby(['lender_id_x', 'lender_id_y'], sort=False).tags.apply(nunique, meta=('tags', 'int64'))\n",
    "print(\"number of divisior\", len(share_tags_ds_dask_collection.divisions))\n",
    "\n",
    "share_tags_ds_dask_collection_persist = client.persist(share_tags_ds_dask_collection)\n",
    "share_tags_ds_dask_collection_persist.dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "lender_tag_ds = lender_tag_ds.sort_values(by=['tags', 'lender_id'])\n",
    "lender_tag_ds.reset_index(drop=True, inplace=True) # make sure the input index is monotonically-increasing\n",
    "ddf : dask_cudf.DataFrame = dask_cudf.from_cudf(lender_tag_ds, sort=False, chunksize=1024, npartitions=1024) # nparition < number of unique tags\n",
    "# ddf : dask_cudf.DataFrame = dask_cudf.from_cudf(lender_tag_ds, npartitions=32) # nparition < number of unique tags\n",
    "merged : dask_cudf.DataFrame = ddf.merge(ddf, on='tags')\n",
    "merged = merged.repartition(npartitions=8192)\n",
    "# merged_meta = cudf.DataFrame(columns=['lender_id_x', 'lender_id_y', 'tags'], dtype={'lender_id_x': 'uint32', 'lender_id_y': 'uint32', 'tags': 'category'})\n",
    "filtered : dask_cudf.DataFrame = merged[merged['lender_id_x'] > merged['lender_id_y']]\n",
    "# filtered : dask_cudf.DataFrame = filtered.repartition(npartitions=8192)\n",
    "\n",
    "\n",
    "def nunique(series):\n",
    "    return series.nunique()\n",
    "\n",
    "share_tags_ds_dask_collection : dask_cudf.DataFrame = filtered.groupby(['lender_id_x', 'lender_id_y'], sort=False).tags.apply(nunique, meta=('tags', 'int64'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "excute the computatation in background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(share_tags_ds_dask_collection_persist.dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut = share_tags_ds_dask_collection_persist.dask[('nunique-af4acf0676342f0939f34bea6059690e', 999)]\n",
    "fut.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_gathered = client.gather(filtered_persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_tags_ds_gathered = client.gather(share_tags_ds_dask_collection_persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_tags_ds = share_tags_ds_gathered.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_tags_ds = share_tags_ds.rename('common_tags_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_tags_ds = share_tags_ds.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_tags_ds.to_parquet(\"share_tags_ds_1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazada = cudf.read_parquet(\"share_tags_ds_1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazada.sort_values('common_tags_count', ascending=False).reset_index().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `cuGRAPH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cugraph as cnx\n",
    "\n",
    "G = cnx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
