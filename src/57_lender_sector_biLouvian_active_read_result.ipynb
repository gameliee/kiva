{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from biLouvian_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_files = glob.glob(\"checkpoints/LS_bipartite_active*.csv\")\n",
    "matching_files = sorted(matching_files)\n",
    "\n",
    "file_regex = r\"bipartite_active_from(?P<date_from>\\d{4}-\\d\\d-\\d\\d).*to(?P<date_to>\\d{4}-\\d\\d-\\d\\d)\"\n",
    "\n",
    "results: List[CommunityResultTime] = []\n",
    "for edgelist in matching_files:\n",
    "    edgelist = os.path.splitext(edgelist)[0]\n",
    "    print(edgelist)\n",
    "\n",
    "    matches = re.finditer(file_regex, edgelist, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        date_from = match.group(\"date_from\")\n",
    "        date_to = match.group(\"date_to\")\n",
    "\n",
    "    mutaraplus = result_mutaraplus(edgelist)\n",
    "    comm_result = result_community(edgelist)\n",
    "\n",
    "    comm_time_result = CommunityResultTime(\n",
    "        community=comm_result,\n",
    "        country=\"all\",\n",
    "        time_from=datetime.strptime(date_from, \"%Y-%m-%d\"),\n",
    "        time_to=datetime.strptime(date_to, \"%Y-%m-%d\"),\n",
    "    )\n",
    "    results.append(comm_time_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# calculate the similarity between pairs of coclusters in a and b\n",
    "positions = {}\n",
    "\n",
    "results = sorted(results, key=lambda x: x.time_from)\n",
    "for t, pair in enumerate(zip(results[:-1], results[1:])):\n",
    "    a, b = pair\n",
    "    for i, cocluster_a in enumerate(a.community.coclusters):\n",
    "        G.add_node(\n",
    "            cocluster_a, time_from=a.time_from, label=cocluster_a.first.member, viz={\"position\": {\"x\": t, \"y\": i}}\n",
    "        )\n",
    "        positions[cocluster_a] = np.array([t, i])\n",
    "        for j, cocluster_b in enumerate(b.community.coclusters):\n",
    "            G.add_node(\n",
    "                cocluster_b,\n",
    "                time_from=b.time_from,\n",
    "                label=cocluster_b.first.member,\n",
    "                viz={\"position\": {\"x\": t + 1, \"y\": j}},\n",
    "            )\n",
    "            positions[cocluster_b] = np.array([t + 1, j])\n",
    "            sim_tag = cocluster_a.similarity_first(cocluster_b)\n",
    "            sim_lender = cocluster_a.similarity_second(cocluster_b)\n",
    "            sim = min(sim_tag, sim_lender)\n",
    "            # sim = cocluster_a.similarity(cocluster_b)\n",
    "            if sim > -100.0:\n",
    "                G.add_edge(\n",
    "                    cocluster_a,\n",
    "                    cocluster_b,\n",
    "                    weight=sim,\n",
    "                    sim_tag=sim_tag,\n",
    "                    sim_lender=sim_lender,\n",
    "                    label=str((round(sim_lender, 2), round(sim_tag, 2))),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the attributes 'color' from all edges\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if \"color\" in data:\n",
    "        del data[\"color\"]\n",
    "\n",
    "# Iterate over the nodes in the graph\n",
    "for node in G.nodes:\n",
    "    # get the incomming edges of the current node\n",
    "    incoming_edges = G.in_edges(node, data=True)\n",
    "\n",
    "    # Find the edge with the highest weight\n",
    "    max_weight = 0\n",
    "    max_weight_edge = None\n",
    "    for edge in incoming_edges:\n",
    "        weight = edge[2][\"weight\"]\n",
    "        if weight > max_weight:\n",
    "            max_weight = weight\n",
    "            max_weight_edge = edge\n",
    "\n",
    "    # Highlight the edge with the highest weight\n",
    "    if max_weight_edge is not None:\n",
    "        G[max_weight_edge[0]][max_weight_edge[1]][\"color\"] = \"red\"\n",
    "\n",
    "# Set the edge colors based on the 'color' attribute\n",
    "edge_colors = [G[u][v].get(\"color\", \"gray\") for u, v in G.edges]\n",
    "edge_weights = [data[\"weight\"] for _, _, data in G.edges(data=True)]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# expand the posision of the nodes\n",
    "zoom = 2\n",
    "pos = {k: v * zoom for k, v in positions.items()}\n",
    "\n",
    "# Draw the graph with highlighted edges\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=False,\n",
    "    node_size=100,\n",
    "    node_color=\"lightblue\",\n",
    "    edge_color=edge_colors,\n",
    "    width=edge_weights,\n",
    "    arrowsize=5,\n",
    ")\n",
    "\n",
    "edge_labels = {(u, v): data.get(\"label\") for u, v, data in G.edges(data=True)}\n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.38, alpha=0.7)\n",
    "\n",
    "# Add time_from at bottom of each column\n",
    "for t, result in enumerate(results):\n",
    "    plt.text(t * zoom, -1, result.time_from.strftime(\"%Y-%m-%d\"), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add text box in the top right corner\n",
    "plt.text(\n",
    "    6,\n",
    "    8,\n",
    "    \"Label: (sim_lender, sim_tag)\\nsimilarity between coclusters\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime to string because gexf cannot serialize datetime\n",
    "for node, data in G.nodes(data=True):\n",
    "    data[\"time_from\"] = data[\"time_from\"].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "nx.write_gexf(G, \"checkpoints/LS_bipartite_active_cocluster_similarity.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "for t, pair in enumerate(zip(results[:-1], results[1:])):\n",
    "    a, b = pair\n",
    "    # get V2 community from a\n",
    "    real_clusters = []\n",
    "    for cocluster in a.community.coclusters:\n",
    "        assert cocluster.second.type == VertexType.V2  # lender\n",
    "        real_clusters.append(cocluster.second.member)\n",
    "\n",
    "    # get V2 community from b\n",
    "    computed_clusters = []\n",
    "    for cocluster in b.community.coclusters:\n",
    "        assert cocluster.second.type == VertexType.V2  # lender\n",
    "        computed_clusters.append(cocluster.second.member)\n",
    "\n",
    "    similarity.append(\n",
    "        {\n",
    "            \"from\": a.time_from.strftime(\"%Y-%m-%d\"),\n",
    "            \"to\": b.time_from.strftime(\"%Y-%m-%d\"),\n",
    "            \"quality\": quality_measure(real_clusters, computed_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "similarity = pd.DataFrame(similarity)\n",
    "print(similarity.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attemp to draw again, better now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = list(G.edges(data=True))\n",
    "edge_list_table = pd.DataFrame(edge_list, columns=[\"Source\", \"Target\", \"EdgeAttributes\"])\n",
    "edge_list_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_attributes = pd.DataFrame(G.nodes(data=True), columns=[\"Node\", \"NodeAttributes\"])\n",
    "node_attributes[[\"Node\", \"NodeAttributes\"]].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_table = edge_list_table.merge(node_attributes, left_on=\"Target\", right_on=\"Node\")\n",
    "edge_list_table.drop(columns=[\"Node\"], inplace=True)\n",
    "edge_list_table.rename(columns={\"NodeAttributes\": \"TargetAttributes\"}, inplace=True)\n",
    "edge_list_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_table = edge_list_table.merge(node_attributes, left_on=\"Source\", right_on=\"Node\")\n",
    "edge_list_table.drop(columns=[\"Node\"], inplace=True)\n",
    "edge_list_table.rename(columns={\"NodeAttributes\": \"SourceAttributes\"}, inplace=True)\n",
    "edge_list_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_table[edge_list_table.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_table[\"source_1\"] = edge_list_table[\"Source\"].apply(lambda x: x.first)\n",
    "edge_list_table[\"source_2\"] = edge_list_table[\"Source\"].apply(lambda x: x.second)\n",
    "edge_list_table[\"source_end_time\"] = edge_list_table[\"SourceAttributes\"].apply(lambda x: x[\"time_from\"])\n",
    "edge_list_table[\"target_1\"] = edge_list_table[\"Target\"].apply(lambda x: x.first)\n",
    "edge_list_table[\"target_2\"] = edge_list_table[\"Target\"].apply(lambda x: x.second)\n",
    "edge_list_table[\"target_end_time\"] = edge_list_table[\"TargetAttributes\"].apply(lambda x: x[\"time_from\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = pd.json_normalize(edge_list_table[\"EdgeAttributes\"])\n",
    "edge_list_table = pd.concat([edge_list_table, expanded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = edge_list_table[\n",
    "    [\n",
    "        \"source_end_time\",\n",
    "        \"source_2\",\n",
    "        \"source_1\",\n",
    "        \"target_end_time\",\n",
    "        \"target_2\",\n",
    "        \"target_1\",\n",
    "        \"sim_lender\",\n",
    "        \"sim_tag\",\n",
    "        \"weight\",\n",
    "    ]\n",
    "].copy()\n",
    "display.rename(columns={\"target_2\": \"community_lender\", \"target_1\": \"community_tag\"}, inplace=True)\n",
    "# display['community_lender'] = display['community_lender'].apply(lambda x: str(x.member))\n",
    "# display['community_tag'] = display['community_tag'].astype(str)\n",
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display[display[\"weight\"] >= 0.1]\n",
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri = display.loc[[12, 11, 18]].reset_index(drop=True)\n",
    "agri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (\n",
    "    agri[[\"source_end_time\", \"source_2\", \"source_1\"]]\n",
    "    .loc[[0]]\n",
    "    .rename(columns={\"source_end_time\": \"target_end_time\", \"source_2\": \"community_lender\", \"source_1\": \"community_tag\"})\n",
    ")\n",
    "b = agri[[\"target_end_time\", \"community_lender\", \"community_tag\", \"sim_lender\", \"sim_tag\"]]\n",
    "agri = pd.concat([a, b], axis=0).reset_index(drop=True)\n",
    "agri.rename(\n",
    "    columns={\n",
    "        \"target_end_time\": \"time\",\n",
    "        \"sim_lender\": \"lender_similarity_to_lastyear\",\n",
    "        \"sim_tag\": \"tag_similarity_to_last_year\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "agri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolatex(_df: pd.DataFrame) -> str:\n",
    "    latex = (\n",
    "        _df.to_latex(index=False)\n",
    "        .replace(\"NaN\", \" - \")\n",
    "        .replace(\"_\", \"\\_\")\n",
    "        .replace(\"\\\\toprule\", \"\\hline\")\n",
    "        .replace(\"\\midrule\", \"\\hline\")\n",
    "        .replace(\"\\\\bottomrule\", \"\\hline\")\n",
    "    )\n",
    "    return (\n",
    "        \"\"\"\\\\begin{table}[H]\n",
    "\t\\centering\n",
    "\t\\\\resizebox{\\\\textwidth}{!}{%\n",
    "        \"\"\"\n",
    "        + latex\n",
    "        + \"\"\"\n",
    "    }\n",
    "    \\caption{Basic statistics of some bipartite graph datasets}\n",
    "\t% \\label{tab:bipartites-statistics}\n",
    "    \\end{table}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(tolatex(agri))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
