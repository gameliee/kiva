{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from biLouvian_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_files = glob.glob(\"checkpoints/LS_bipartite_active*.csv\")\n",
    "matching_files = sorted(matching_files)\n",
    "\n",
    "file_regex = r\"bipartite_active_from(?P<date_from>\\d{4}-\\d\\d-\\d\\d).*to(?P<date_to>\\d{4}-\\d\\d-\\d\\d)\"\n",
    "comm_regex = r\"^Community (?P<community_id>\\d+)\\[(?P<vertex_type>V\\d+)\\]: (?P<vertexes>.*)$\"\n",
    "clus_regex = r\"^CoCluster (?P<cocluster_id>\\d+):(?P<vertex_type>V\\d+)\\((?P<a_id>\\d+)\\)-(?P<b_id>\\d+)$\"\n",
    "\n",
    "results: List[CommunityResultTime] = []\n",
    "for edgelist in matching_files:\n",
    "    edgelist = os.path.splitext(edgelist)[0]\n",
    "    print(edgelist)\n",
    "\n",
    "    matches = re.finditer(file_regex, edgelist, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        date_from = match.group(\"date_from\")\n",
    "        date_to = match.group(\"date_to\")\n",
    "\n",
    "    community_file = edgelist + \"_ResultsCommunities.txt\"\n",
    "    if not os.path.exists(community_file):\n",
    "        continue\n",
    "    with open(community_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    clusters: List[ClusterItem] = []\n",
    "    matches = re.finditer(comm_regex, text, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        community_id = match.group(\"community_id\")\n",
    "        vertex_type = match.group(\"vertex_type\")\n",
    "        vertexes = match.group(\"vertexes\").split(\", \")[0]\n",
    "        vertexes = vertexes.split(\",\")\n",
    "        # if vertex_type == \"V1\":\n",
    "        # print(community_id, vertex_type, vertexes)\n",
    "        cluster = ClusterItem(community_id=int(community_id), member=set(vertexes), type=VertexType(vertex_type))\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    with open(f\"{edgelist}_ResultsCoClusterCommunities.txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    coclusters: List[CoClusterItem] = []\n",
    "    matches = re.finditer(clus_regex, text, re.MULTILINE)\n",
    "\n",
    "    # NOTE: Becareful, the cocluster could be duplicated. like this:\n",
    "    # CoCluster 1:V1(1)-2\n",
    "    # CoCluster 2:V2(2)-1\n",
    "\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        cocluster_id = match.group(\"cocluster_id\")\n",
    "        vertex_type = match.group(\"vertex_type\")\n",
    "        a_id = match.group(\"a_id\")\n",
    "        b_id = match.group(\"b_id\")\n",
    "\n",
    "        # find the cluster with id a_id in clusters\n",
    "        for cluster in clusters:\n",
    "            if cluster.community_id == int(a_id):\n",
    "                a = cluster\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"cannot find cluster with id {a_id}\")\n",
    "\n",
    "        # do the same for b_id\n",
    "        for cluster in clusters:\n",
    "            if cluster.community_id == int(b_id):\n",
    "                b = cluster\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"cannot find cluster with id {b_id}\")\n",
    "\n",
    "        if VertexType(vertex_type) != \"V1\":\n",
    "            # swap a and b\n",
    "            a, b = b, a\n",
    "            a_id, b_id = b_id, a_id\n",
    "\n",
    "        # check if the cocluster (a_id, b_id) is already in the coclusters list\n",
    "        for _co in coclusters:\n",
    "            if _co.first.community_id == int(a_id) and _co.second.community_id == int(b_id):\n",
    "                break\n",
    "        else:\n",
    "            # if not, add it\n",
    "            cocluster = CoClusterItem(\n",
    "                cocluster_id=int(cocluster_id),\n",
    "                first=a,\n",
    "                second=b,\n",
    "            )\n",
    "            coclusters.append(cocluster)\n",
    "\n",
    "    comm_result = CommunityResult(\n",
    "        clusters=set(clusters),\n",
    "        coclusters=set(coclusters),\n",
    "    )\n",
    "\n",
    "    comm_time_result = CommunityResultTime(\n",
    "        community=comm_result,\n",
    "        country=\"all\",\n",
    "        time_from=datetime.strptime(date_from, \"%Y-%m-%d\"),\n",
    "        time_to=datetime.strptime(date_to, \"%Y-%m-%d\"),\n",
    "    )\n",
    "    results.append(comm_time_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# calculate the similarity between pairs of coclusters in a and b\n",
    "positions = {}\n",
    "\n",
    "results = sorted(results, key=lambda x: x.time_from)\n",
    "for t, pair in enumerate(zip(results[:-1], results[1:])):\n",
    "    a, b = pair\n",
    "    for i, cocluster_a in enumerate(a.community.coclusters):\n",
    "        G.add_node(cocluster_a, time_from=a.time_from, label=cocluster_a.first.member)\n",
    "        positions[cocluster_a] = np.array([t, i])\n",
    "        for j, cocluster_b in enumerate(b.community.coclusters):\n",
    "            G.add_node(cocluster_b, time_from=b.time_from, label=cocluster_b.first.member)\n",
    "            positions[cocluster_b] = np.array([t + 1, j])\n",
    "            sim_tag = cocluster_a.similarity_first(cocluster_b)\n",
    "            sim_lender = cocluster_a.similarity_second(cocluster_b)\n",
    "            sim = min(sim_tag, sim_lender)\n",
    "            # sim = cocluster_a.similarity(cocluster_b)\n",
    "            if sim > 0.0:\n",
    "                G.add_edge(\n",
    "                    cocluster_a,\n",
    "                    cocluster_b,\n",
    "                    weight=sim,\n",
    "                    sim_tag=sim_tag,\n",
    "                    sim_lender=sim_lender,\n",
    "                    label=str((round(sim_tag, 2), round(sim_lender, 2))),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the attributes 'color' from all edges\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if \"color\" in data:\n",
    "        del data[\"color\"]\n",
    "\n",
    "# Iterate over the nodes in the graph\n",
    "for node in G.nodes:\n",
    "    # get the incomming edges of the current node\n",
    "    incoming_edges = G.in_edges(node, data=True)\n",
    "\n",
    "    # Find the edge with the highest weight\n",
    "    max_weight = 0\n",
    "    max_weight_edge = None\n",
    "    for edge in incoming_edges:\n",
    "        weight = edge[2][\"weight\"]\n",
    "        if weight > max_weight:\n",
    "            max_weight = weight\n",
    "            max_weight_edge = edge\n",
    "\n",
    "    # Highlight the edge with the highest weight\n",
    "    if max_weight_edge is not None:\n",
    "        G[max_weight_edge[0]][max_weight_edge[1]][\"color\"] = \"red\"\n",
    "\n",
    "# Set the edge colors based on the 'color' attribute\n",
    "edge_colors = [G[u][v].get(\"color\", \"gray\") for u, v in G.edges]\n",
    "edge_weights = [data[\"weight\"] for _, _, data in G.edges(data=True)]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# expand the posision of the nodes\n",
    "zoom = 2\n",
    "pos = {k: v * zoom for k, v in positions.items()}\n",
    "\n",
    "# Draw the graph with highlighted edges\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=False,\n",
    "    node_size=100,\n",
    "    node_color=\"lightblue\",\n",
    "    edge_color=edge_colors,\n",
    "    width=edge_weights,\n",
    "    arrowsize=5,\n",
    ")\n",
    "\n",
    "edge_labels = {\n",
    "    (u, v): (round(data.get(\"sim_tag\", 0), 2), round(data.get(\"sim_lender\", 0), 2)) for u, v, data in G.edges(data=True)\n",
    "}\n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.38, alpha=0.7)\n",
    "\n",
    "# Add time_from at bottom of each column\n",
    "for t, result in enumerate(results):\n",
    "    plt.text(t * zoom, -1, result.time_from.strftime(\"%Y-%m-%d\"), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add text box in the top right corner\n",
    "plt.text(\n",
    "    14,\n",
    "    10,\n",
    "    \"Label: (sim_tag, sim_lender)\\nsimilarity between coclusters\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime to string because gexf cannot serialize datetime\n",
    "for node, data in G.nodes(data=True):\n",
    "    data[\"time_from\"] = data[\"time_from\"].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "nx.write_gexf(G, \"checkpoints/LS_bipartite_active_cocluster_similarity.gexf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
