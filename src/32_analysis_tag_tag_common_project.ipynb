{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysis the graph of tags\n",
    "\n",
    "![common tag](./images/graph_schema-TAG_TAG_COMMON_PROJECT.png)\n",
    "\n",
    "we have to note that, the production above is by no mean the weigh we should consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and define the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visiable only some GPUs\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cudf\n",
    "import cugraph as cnx\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tag = cudf.read_csv(\"../data/gen/project_tags.csv\")\n",
    "project_tag.rename(columns={\":START_ID(Loan-ID)\": \"project_id\", \":END_ID\": \"tag\"}, inplace=True)\n",
    "project_tag.drop(columns=[\":TYPE\"], inplace=True)\n",
    "# project_tag[\"tag\"] = project_tag[\"tag\"].astype(\"category\").cat.as_ordered() # not work\n",
    "project_tag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, the above is the edge-list of a bipartite graph, where the node types is `project_id` and `tag`.\n",
    "To study such graphs, with the hypothesis that there might have a *community* of tags, which contribute a same type of impact.\n",
    "\n",
    "Now, do a *bipartite* project on the *tag*. We will use the following weight. Support that there are 2 tags: `tag1` and `tag2`. The corresponding project set for the tags is $T_1$ and $T_2$. We could you the \"intersaction over union\" as a weight, that is\n",
    "\n",
    "$$weight(tag1, tag2) = \\frac{|T_1 \\cap T_2|}{|T_1 \\cup T_2|}$$\n",
    "\n",
    "Notice that the above weight is symmetric, in a way that $$weight(t1, t2) = weight(t2, t1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project the bipartite graph onto the *tag* nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = project_tag.merge(project_tag, on=\"project_id\")\n",
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the above table, we have a project_id and the 2 tags have been in that project.   \n",
    "Notice that, when doing the merge, the `tag_x` and `tag_y` could be the same. We will filter out that.\n",
    "Also because of the symmetrically nature of the weight. We will keep only half of the table, where `tag_x` > `tag_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = merged[merged[\"tag_x\"] > merged[\"tag_y\"]]\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = filtered.groupby([\"tag_x\", \"tag_y\"]).nunique()\n",
    "inter.rename(columns={\"project_id\": \"union\"}, inplace=True)\n",
    "inter.reset_index(inplace=True)\n",
    "inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that\n",
    "\n",
    "$${|T_1 \\cup T_2|} = |T_1| + |T_2| - |T_1 \\cap T_2|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_by_tag = project_tag.groupby(\"tag\").nunique()\n",
    "pro_by_tag.rename(columns={\"project_id\": \"nunique\"}, inplace=True)\n",
    "pro_by_tag.reset_index(inplace=True)\n",
    "pro_by_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (\n",
    "    inter.merge(pro_by_tag, left_on=\"tag_x\", right_on=\"tag\")\n",
    "    .drop(columns=[\"tag\"])\n",
    "    .rename(columns={\"nunique\": \"nunique_x\"})\n",
    ")\n",
    "pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (\n",
    "    pair.merge(pro_by_tag, left_on=\"tag_y\", right_on=\"tag\")\n",
    "    .drop(columns=[\"tag\"])\n",
    "    .rename(columns={\"nunique\": \"nunique_y\"})\n",
    ")\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair[\"overlap\"] = pair[\"nunique_x\"] + pair[\"nunique_y\"] - pair[\"union\"]\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair[\"weight\"] = pair[\"union\"] / pair[\"overlap\"]\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let try `networkx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = pair[[\"tag_x\", \"tag_y\", \"weight\"]].to_pandas()\n",
    "edges_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Gnx = nx.Graph()\n",
    "Gnx = nx.from_pandas_edgelist(edges_df, source=\"tag_x\", target=\"tag_y\", edge_attr=\"weight\")\n",
    "edge_vmin = edges_df[\"weight\"].min()\n",
    "edge_vmax = edges_df[\"weight\"].max()\n",
    "print(Gnx.number_of_nodes(), Gnx.number_of_edges(), edge_vmin, edge_vmax)\n",
    "nx.write_gexf(Gnx, \"../data/gen/tag_tag_common_loans.gexf\")  # use this one for gephi\n",
    "\n",
    "# draw the graph in circular layout, with labels, and map the color of the edges with the attribute weight\n",
    "weights = [Gnx[u][v][\"weight\"] for u, v in Gnx.edges()]\n",
    "nx.draw_circular(Gnx, with_labels=True, edge_color=weights, edge_cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate nodes degree and store in a dataframe\n",
    "degree = Gnx.degree(weight=\"weight\")\n",
    "node_df = pd.DataFrame.from_dict(dict(degree), orient=\"index\", columns=[\"degree\"])\n",
    "node_df.index.name = \"tag\"\n",
    "node_df.reset_index(inplace=True)\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive community finding in the graph using louvain algorithm\n",
    "community = nx.community.louvain_communities(Gnx, resolution=1.1, seed=123)\n",
    "community_index = {node: i for i, community in enumerate(community) for node in community}\n",
    "partition = pd.DataFrame.from_dict(community_index, orient=\"index\", columns=[\"louvain_community\"])\n",
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = node_df.merge(partition, left_on=\"tag\", right_index=True)\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forceatlas2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(200, 400))\n",
    "node_df[\"degree_scaled\"] = scaler.fit_transform(node_df[[\"degree\"]])\n",
    "\n",
    "nodes = node_df.tag.values\n",
    "nodes_size = node_df.degree_scaled.values\n",
    "node_color = node_df.louvain_community.values\n",
    "\n",
    "l = forceatlas2.forceatlas2_networkx_layout(\n",
    "    Gnx, niter=1000, scalingRatio=20.0, strongGravityMode=True, gravity=0.05\n",
    ")  # Optionally specify iteration count\n",
    "nx.draw_networkx(\n",
    "    Gnx,\n",
    "    l,\n",
    "    nodelist=nodes,\n",
    "    node_size=nodes_size,\n",
    "    with_labels=True,\n",
    "    node_color=node_color,\n",
    "    cmap=plt.cm.viridis,\n",
    "    edge_color=weights,\n",
    "    edge_cmap=plt.cm.Reds,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add community information to nodes\n",
    "for node, community in community_index.items():\n",
    "    Gnx.nodes[node][\"community_louvain\"] = community\n",
    "nx.write_gexf(Gnx, \"../data/gen/tag_tag_common_loans.gexf\")  # use this one for gephi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
