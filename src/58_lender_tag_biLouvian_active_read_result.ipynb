{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from biLouvian_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_files = glob.glob(\"checkpoints/LT_bipartite_active*.csv\")\n",
    "matching_files = sorted(matching_files)\n",
    "\n",
    "file_regex = r\"bipartite_active_from(?P<date_from>\\d{4}-\\d\\d-\\d\\d).*to(?P<date_to>\\d{4}-\\d\\d-\\d\\d)\"\n",
    "\n",
    "results: List[CommunityResultTime] = []\n",
    "for edgelist in matching_files:\n",
    "    edgelist = os.path.splitext(edgelist)[0]\n",
    "    print(edgelist)\n",
    "\n",
    "    matches = re.finditer(file_regex, edgelist, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        date_from = match.group(\"date_from\")\n",
    "        date_to = match.group(\"date_to\")\n",
    "\n",
    "    mutaraplus = result_mutaraplus(edgelist)\n",
    "    comm_result = result_community(edgelist)\n",
    "\n",
    "    comm_time_result = CommunityResultTime(\n",
    "        community=comm_result,\n",
    "        country=\"all\",\n",
    "        time_from=datetime.strptime(date_from, \"%Y-%m-%d\"),\n",
    "        time_to=datetime.strptime(date_to, \"%Y-%m-%d\"),\n",
    "    )\n",
    "    results.append(comm_time_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# calculate the similarity between pairs of coclusters in a and b\n",
    "positions = {}\n",
    "\n",
    "results = sorted(results, key=lambda x: x.time_from)\n",
    "for t, pair in enumerate(zip(results[:-1], results[1:])):\n",
    "    a, b = pair\n",
    "    for i, cocluster_a in enumerate(a.community.coclusters):\n",
    "        G.add_node(cocluster_a, time_from=a.time_from, label=cocluster_a.first.member)\n",
    "        positions[cocluster_a] = np.array([t, i])\n",
    "        for j, cocluster_b in enumerate(b.community.coclusters):\n",
    "            G.add_node(cocluster_b, time_from=b.time_from, label=cocluster_b.first.member)\n",
    "            positions[cocluster_b] = np.array([t + 1, j])\n",
    "            sim_tag = cocluster_a.similarity_first(cocluster_b)\n",
    "            sim_lender = cocluster_a.similarity_second(cocluster_b)\n",
    "            sim = min(sim_tag, sim_lender)\n",
    "            # sim = cocluster_a.similarity(cocluster_b)\n",
    "            if sim > 0.0:\n",
    "                G.add_edge(\n",
    "                    cocluster_a,\n",
    "                    cocluster_b,\n",
    "                    weight=sim,\n",
    "                    sim_tag=sim_tag,\n",
    "                    sim_lender=sim_lender,\n",
    "                    label=str((round(sim_tag, 2), round(sim_lender, 2))),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the attributes 'color' from all edges\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if \"color\" in data:\n",
    "        del data[\"color\"]\n",
    "\n",
    "# Iterate over the nodes in the graph\n",
    "for node in G.nodes:\n",
    "    # get the incomming edges of the current node\n",
    "    incoming_edges = G.in_edges(node, data=True)\n",
    "\n",
    "    # Find the edge with the highest weight\n",
    "    max_weight = 0\n",
    "    max_weight_edge = None\n",
    "    for edge in incoming_edges:\n",
    "        weight = edge[2][\"weight\"]\n",
    "        if weight > max_weight:\n",
    "            max_weight = weight\n",
    "            max_weight_edge = edge\n",
    "\n",
    "    # Highlight the edge with the highest weight\n",
    "    if max_weight_edge is not None:\n",
    "        G[max_weight_edge[0]][max_weight_edge[1]][\"color\"] = \"red\"\n",
    "\n",
    "# Set the edge colors based on the 'color' attribute\n",
    "edge_colors = [G[u][v].get(\"color\", \"gray\") for u, v in G.edges]\n",
    "edge_weights = [data[\"weight\"] for _, _, data in G.edges(data=True)]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(6, 3))\n",
    "\n",
    "# expand the posision of the nodes\n",
    "zoom = 2\n",
    "pos = {k: v * zoom for k, v in positions.items()}\n",
    "\n",
    "# Draw the graph with highlighted edges\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=False,\n",
    "    node_size=100,\n",
    "    node_color=\"lightblue\",\n",
    "    edge_color=edge_colors,\n",
    "    width=edge_weights,\n",
    "    arrowsize=5,\n",
    ")\n",
    "\n",
    "edge_labels = {\n",
    "    (u, v): (round(data.get(\"sim_tag\", 0), 2), round(data.get(\"sim_lender\", 0), 2)) for u, v, data in G.edges(data=True)\n",
    "}\n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.38, alpha=0.7)\n",
    "\n",
    "# Add time_from at bottom of each column\n",
    "for t, result in enumerate(results):\n",
    "    plt.text(t * zoom, -1, result.time_from.strftime(\"%Y-%m-%d\"), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add text box in the top right corner\n",
    "plt.text(\n",
    "    0,\n",
    "    2,\n",
    "    \"Label: (sim_tag, sim_lender)\\nsimilarity between coclusters\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime to string because gexf cannot serialize datetime\n",
    "for node, data in G.nodes(data=True):\n",
    "    data[\"time_from\"] = data[\"time_from\"].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "nx.write_gexf(G, \"checkpoints/LT_bipartite_active_cocluster_similarity.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to calculate the similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "for t, pair in enumerate(zip(results[:-1], results[1:])):\n",
    "    a, b = pair\n",
    "    # get V2 community from a\n",
    "    real_clusters = []\n",
    "    for cocluster in a.community.coclusters:\n",
    "        assert cocluster.second.type == VertexType.V2  # lender\n",
    "        real_clusters.append(cocluster.second.member)\n",
    "\n",
    "    # get V2 community from b\n",
    "    computed_clusters = []\n",
    "    for cocluster in b.community.coclusters:\n",
    "        assert cocluster.second.type == VertexType.V2  # lender\n",
    "        computed_clusters.append(cocluster.second.member)\n",
    "\n",
    "    similarity.append(\n",
    "        {\"from\": a.time_from, \"to\": b.time_from, \"quality\": quality_measure(real_clusters, computed_clusters)}\n",
    "    )\n",
    "\n",
    "similarity = pd.DataFrame(similarity)\n",
    "print(similarity.to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
