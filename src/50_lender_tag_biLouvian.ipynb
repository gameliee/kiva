{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameter cell\n",
    "DEVICES = \"1,2\"\n",
    "FROM = \"2019-01-01\"\n",
    "TO = \"2020-01-01\"\n",
    "COUNTRY = \"Vietnam\"\n",
    "ORDER = 1  # will be pass to param order in biLouvian call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICES\n",
    "\n",
    "import re\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cudf\n",
    "import networkx as nx\n",
    "from cuml.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data and filter by the Paramteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cudf.read_parquet(\"../fulldata/kiva_activity_2023-08-28T11-09-39.parquet\")\n",
    "ds[\"sector_name\"] = ds[\"sector_name\"].astype(\"category\")\n",
    "ds[\"geocode_country_name\"] = ds[\"geocode_country_name\"].astype(\"category\")\n",
    "ds[\"activity_name\"] = ds[\"activity_name\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dropna(axis=0, how=\"all\", inplace=True)\n",
    "print(len(ds))\n",
    "ds.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COUNTRY.lower() != \"all\":\n",
    "    ds = ds[ds[\"geocode_country_name\"] == COUNTRY]\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to limit the timeline, because I am not yet comfortable to work with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[(ds.fundraisingDate >= FROM) & (ds.fundraisingDate < TO)]\n",
    "\"the number of Loans (might duplicated) under investigation is\", len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.rename(columns={\"id\": \"project_id\", \"name\": \"project_name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicated Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are Projects which have a same `project_id` but different `fundedAmount`\n",
    "It might because the query time is different\n",
    "Here, only keep records which have the highest `fundedAmount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds.groupby(\"project_id\", group_keys=False)[[\"loanFundraisingInfo_fundedAmount\"]].idxmax()\n",
    "iloc = temp[\"loanFundraisingInfo_fundedAmount\"].values  # NOTE: just iloc, not loc\n",
    "ds = ds.iloc[iloc]\n",
    "del iloc\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == len(ds[ds.duplicated(subset=[\"project_id\"], keep=False)].sort_values(by=[\"project_id\"]))  # no duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"the number of Projects (no duplicated) under investigation is\", len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `Lender-Project-Tag` df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ds.explode(\"lendingActions_values\")\n",
    "len(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some loans that has no lender\n",
    "ads.dropna(subset=[\"lendingActions_values\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict processing cant be done in cuDF, so convert to pandas\n",
    "adf = ads.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf[\"lender_id\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"lender\"][\"id\"], axis=1).astype(int)\n",
    "adf[\"lender_name\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"lender\"][\"name\"], axis=1)\n",
    "adf[\"lender_publicId\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"lender\"][\"publicId\"], axis=1)\n",
    "adf[\"loan_shareAmount\"] = adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"shareAmount\"], axis=1).astype(float)\n",
    "adf[\"loan_date\"] = pd.to_datetime(\n",
    "    adf.progress_apply(lambda x: x[\"lendingActions_values\"][\"latestSharePurchaseDate\"], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuDF do not work with timezone yet\n",
    "adf[\"loan_date\"] = adf[\"loan_date\"].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.drop([\"lendingActions_values\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = cudf.from_pandas(adf)\n",
    "del adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == ads.duplicated(subset=[\"project_id\", \"lender_id\", \"loan_shareAmount\", \"loan_date\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads[\"loan_id\"] = cp.arange(len(ads[\"lender_id\"])) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explode `tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ads.explode(\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many Loans that do not have tags\n",
    "ads[ads[\"tags\"].isna()].project_id.unique().count(), \"~\", ads[\n",
    "    ads[\"tags\"].isna()\n",
    "].project_id.unique().count() / ads.project_id.unique().count() * 100, \"percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tag call `empty`\n",
    "# ads.dropna(subset=[\"tags\"], inplace=True)\n",
    "ads[[\"tags\"]].fillna(\"empty\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove some tags \n",
    "The folowing tags should be remove, because it isn't visible to Users:  \n",
    "- `user_favorite`\n",
    "- `user_like`\n",
    "- `volunteer_like`\n",
    "- `volunteer_pick`\n",
    "\n",
    "If a project **only** have those tags, change all those tags into `empty`, then remove duplicate again.  \n",
    "If a project have other tags rather than those tags, just drop those tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ads[\"tags\"] == \"user_favorite\").sum(), (ads[\"tags\"] == \"user_like\").sum(), (ads[\"tags\"] == \"volunteer_like\").sum(), (\n",
    "    ads[\"tags\"] == \"volunteer_pick\"\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.duplicated().sum()  # NOTE: only work with small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads[\"tags\"] = ads.tags.replace([\"user_favorite\", \"user_like\", \"volunteer_like\", \"volunteer_pick\"], [\"removetag\"] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.drop_duplicates(inplace=True)  # NOTE: only work with small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count tags by loans\n",
    "# NOTE: this method only support small size data, consider using `transform` instead\n",
    "# NOTE: also note that, `transform('nunique')` might not work with cudf yet\n",
    "one_tag_loans = ads.groupby(\"project_id\").tags.nunique(dropna=False) == 1\n",
    "one_tag_loans = one_tag_loans[one_tag_loans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_change_tag = (ads[\"project_id\"].isin(one_tag_loans.index)) & (ads[\"tags\"] == \"removetag\")\n",
    "ads[should_change_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads[should_change_tag].tags = \"empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ads[ads.tags != \"removetag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads[\"tags\"] = ads[\"tags\"].astype(\"category\").cat.as_ordered()\n",
    "ads[\"tags\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the portion of Loans that have no tags?\n",
    "ads[ads.tags == \"empty\"].project_id.nunique(), ads.project_id.nunique(), ads[\n",
    "    ads.tags == \"empty\"\n",
    "].project_id.nunique() / ads.project_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just remove no-tag Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ads[ads.tags != \"empty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove anonymous Lenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"anynomous Lenders\")\n",
    "anons = ads.lender_publicId.str.startswith(\"anon\")\n",
    "ads[anons][[\"lender_id\", \"lender_name\", \"lender_publicId\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those anon\n",
    "ads = ads[~anons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Loans\", ads.project_id.unique().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Lenders\", ads.lender_id.unique().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct `Lender-Tag` bipartite graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edge list of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LT = ads.groupby([\"lender_id\", \"tags\"]).agg(\n",
    "    {\"lender_publicId\": \"first\", \"loan_shareAmount\": \"sum\", \"loan_date\": \"count\"}\n",
    ")\n",
    "LT.reset_index(inplace=True)\n",
    "LT.rename(columns={\"loan_shareAmount\": \"loan_amount\", \"loan_date\": \"loan_count\"}, inplace=True)\n",
    "LT = LT[LT[\"loan_amount\"] > 0]\n",
    "LT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to the format that `biLouvian` can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "LT[\"V1\"] = le1.fit_transform(LT[\"tags\"])\n",
    "le2 = LabelEncoder()\n",
    "LT[\"V2\"] = le2.fit_transform(LT[\"lender_id\"]) + LT[\"V1\"].max() + 1\n",
    "LT.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of vertex\n",
    "vertex_count = LT[\"lender_id\"].nunique() + LT[\"tags\"].nunique()\n",
    "assert vertex_count == LT[\"V1\"].nunique() + LT[\"V2\"].nunique()\n",
    "print(vertex_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary1 = LT[[\"V1\", \"tags\"]].drop_duplicates()\n",
    "dictionary1.rename(columns={\"tags\": \"name\", \"V1\": \"id\"}, inplace=True)\n",
    "dictionary1[\"name\"] = dictionary1[\"name\"].astype(str)\n",
    "dictionary1.sort_values(by=[\"id\"]).tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary2 = LT[[\"V2\", \"lender_publicId\"]].drop_duplicates()\n",
    "dictionary2.rename(columns={\"lender_publicId\": \"name\", \"V2\": \"id\"}, inplace=True)\n",
    "dictionary2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat two dictionaries\n",
    "dictionary = cudf.concat([dictionary1, dictionary2])\n",
    "print(len(dictionary))\n",
    "assert len(dictionary) == vertex_count\n",
    "dictionary.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = f\"checkpoints/LT_bipartite_{COUNTRY}_from{FROM}_to{TO}\"  # the text \"bipartite\" is mandatory\n",
    "filename = f\"{prefix}.csv\"\n",
    "dictfile = f\"{prefix}_Dictionary.txt\"  # \"_Dictionary.txt\" is mandatory\n",
    "LT[[\"V1\", \"V2\", \"loan_amount\"]].to_csv(filename, sep=\"\\t\", header=False, index=False)  # \"\\t\" is mandatory\n",
    "dictionary[[\"id\", \"name\"]].to_csv(dictfile, sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run `biLouvian`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Have to build the `biLouvian` binary first. Refer to `doc/BUILD_BILOUVIAN.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../extra/biLouvian -i $filename -order $ORDER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
