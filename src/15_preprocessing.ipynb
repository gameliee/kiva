{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DEVICES = \"1,2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cudf\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data\n",
    "First, read data in `.jsonl` file format as a pandas data frame\n",
    "Then store the dataframe in `.parquet` format for easy access later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cudf.read_parquet(\"../fulldata/kiva_activity_2023-08-28T11-09-39.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.rename(columns={\"id\": \"project_id\", \"name\": \"project_name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dropna(axis=0, how=\"all\", inplace=True)\n",
    "ds.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data for Vietnam only\n",
    "Filtering, only take `Vietnam` into account\n",
    "Why? Because there are a lot of rows and we try to localize the task\n",
    "ds[\"geocode_country_name\"].value_counts()[\"Vietnam\"]\n",
    "ds = ds[ds[\"geocode_country_name\"] == \"Vietnam\"]\n",
    "Try to limit the timeline, because I am not yet comfortable to work with large data\n",
    "ds = ds[ds.fundraisingDate > \"2020-01-01\"]\n",
    "\"the number of Loans (might duplicated) under investigation is\", len(ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicated `loan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are loans which have a same `id` but different `fundedAmount`\n",
    "It might because the query time is different\n",
    "Here, only keep records which have the highest `fundedAmount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.loc[[9628, 1366545]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds.groupby(\"id\", group_keys=False)[[\"loanFundraisingInfo_fundedAmount\"]].idxmax()\n",
    "iloc = temp[\"loanFundraisingInfo_fundedAmount\"].values  # NOTE: just iloc, not loc\n",
    "ds = ds.iloc[iloc]\n",
    "del iloc\n",
    "del temp\n",
    "ds.loc[[9628, 1366545]]  # see, only keep the one with higher fundedAmount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds.duplicated(subset=[\"id\"], keep=False)].sort_values(by=[\"id\"])  # no duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"the number of Loans (no duplicated) under investigation is\", len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"sector_name\"] = ds[\"sector_name\"].astype(\"category\")\n",
    "ds[\"geocode_country_name\"] = ds[\"geocode_country_name\"].astype(\"category\")\n",
    "ds[\"activity_name\"] = ds[\"activity_name\"].astype(\"category\")\n",
    "ds[\"sector_id\"] = ds[\"sector_id\"].astype(\"uint8\")\n",
    "ds[\"activity_id\"] = ds[\"activity_id\"].astype(\"uint8\")\n",
    "ds[\"lendingActions_totalCount\"] = ds[\"lendingActions_totalCount\"].astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == ds.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create `lender-loan-tag` df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode the `lendingActions_values`, then do dict processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the explosion will require more memmory, the nature choice is to move forward to dask_cudf.  \n",
    "But here, we must process the `dict` data type later.  \n",
    "Hence, just use pandas would be the easiest way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()  # slow, about 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode(\"lendingActions_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"lendingActions_values\"], inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lender_id\"] = df.lendingActions_values.progress_apply(lambda x: x[\"lender\"][\"id\"]).astype(int)\n",
    "df[\"lender_name\"] = df.lendingActions_values.progress_apply(lambda x: x[\"lender\"][\"name\"])\n",
    "df[\"lender_publicId\"] = df.lendingActions_values.progress_apply(lambda x: x[\"lender\"][\"publicId\"])\n",
    "df[\"loan_shareAmount\"] = df.lendingActions_values.progress_apply(lambda x: x[\"shareAmount\"]).astype(float)\n",
    "df[\"loan_date\"] = pd.to_datetime(df.lendingActions_values.progress_apply(lambda x: x[\"latestSharePurchaseDate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"lendingActions_values\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a column call `loan_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.duplicates(subset=[['project_id', 'lender_id', 'lender_name', 'lender_publicId', 'loan_shareAmount', 'loan_date']])\n",
    "assert 0 == df.duplicated(subset=[\"project_id\", \"lender_id\", \"loan_shareAmount\", \"loan_date\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_id\"] = np.arange(len(df[\"lender_id\"])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuDF do not work with timezone yet\n",
    "df[\"loan_date\"] = df[\"loan_date\"].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, expode the `tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode(\"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"checkpoints/explodeddata.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"checkpoints/explodeddata.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Projects\n",
    "df.project_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Lenders\n",
    "df.lender_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many project that doesn't have tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tags_df = df[[\"project_id\", \"fundraisingDate\", \"tags\"]].drop_duplicates()\n",
    "print(len(project_tags_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same result\n",
    "monthly_grouper = pd.Grouper(key=\"fundraisingDate\", freq=\"30d\")\n",
    "perMonth = project_tags_df.groupby(monthly_grouper).agg({\"project_id\": \"nunique\", \"tags\": \"count\"})\n",
    "perMonth.rename(columns={\"project_id\": \"project_count\", \"tags\": \"tag_count\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perMonth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perMonth.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_empty_tags = project_tags_df.groupby(\"project_id\").tags.count() == 0\n",
    "project_empty_tags = project_empty_tags.rename(\"is_empty_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_empty_tags = (\n",
    "    project_tags_df.drop(columns=[\"tags\"])\n",
    "    .drop_duplicates()\n",
    "    .merge(project_empty_tags, left_on=\"project_id\", right_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_per_month = project_empty_tags.groupby(monthly_grouper).agg({\"project_id\": \"nunique\", \"is_empty_tags\": \"sum\"})\n",
    "empty_per_month.rename(columns={\"project_id\": \"count_project\", \"is_empty_tags\": \"count_project_no_tag\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_per_month[\"percentage_no_tag\"] = empty_per_month[\"count_project_no_tag\"] / empty_per_month[\"count_project\"] * 100\n",
    "empty_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_per_month[[\"percentage_no_tag\"]].plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could say that before 2013, projects do not have tags. Tags appeared since 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag preprocessing without dask\n",
    "\n",
    "Here, we just using pandas, because `cudf` cannot load the big parquet file  \n",
    "Becareful, need 3 hours to do the deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_parquet(\"checkpoints/explodeddata.parquet\")\n",
    "# ds = cudf.read_parquet(\"checkpoints/explodeddata.parquet\")\n",
    "# ds = cudf.read_parquet(\"checkpoints/explodeddata_sample_1000.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tag call `empty`\n",
    "ds[\"tags\"] = ds[\"tags\"].fillna(\"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"tags\"] = ds.tags.replace([\"user_favorite\", \"user_like\", \"volunteer_like\", \"volunteer_pick\"], [\"removetag\"] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(partition):\n",
    "    return partition.drop_duplicates(subset=[\"project_id\", \"tags\", \"lender_id\", \"loan_shareAmount\", \"loan_date\"])\n",
    "\n",
    "\n",
    "ds = ds.groupby(\"project_id\").apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_tag_loans = ds.groupby(\"project_id\").tags.transform(\"nunique\") == 1\n",
    "one_tag_loans = one_tag_loans.rename(\"is_single_tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.merge(one_tag_loans.to_frame(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[(ds[\"is_single_tag\"] == True) & (ds[\"tags\"] == \"removetag\")][\"tags\"] = \"empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[ds.tags != \"removetag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"tags\"] = ds[\"tags\"].astype(\"category\").cat.as_ordered()\n",
    "ds[\"tags\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_anon_1 = ds.lender_name.str.lower().str.startswith(\"anonymous\")\n",
    "is_anon_2 = ds.lender_publicId.fillna(\"\").str.startswith(\"anon\")\n",
    "anons = is_anon_1 | is_anon_2\n",
    "print(\"anynomous Lenders\")\n",
    "# print some annons\n",
    "ds[anons][[\"lender_id\", \"lender_name\", \"lender_publicId\"]].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many anons out there?\n",
    "anons.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those anon\n",
    "ds = ds[~anons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_parquet(\"../data/gen/preprocessed_2023-08-28T11-09-39.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/gen/preprocessed_2023-08-28T11-09-39.parquet\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn = df[df[\"geocode_country_name\"] == \"Vietnam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_since_2020 = vn[vn.fundraisingDate > \"2020-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_since_2020 = vn_since_2020[vn_since_2020.tags != \"empty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_since_2020.project_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_since_2020.tags.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_since_2020.lender_id.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
