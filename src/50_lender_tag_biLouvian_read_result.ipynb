{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from biLouvian_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_files = glob.glob(\"checkpoints/LT_bipartite_*.csv\")\n",
    "matching_files = sorted(matching_files)\n",
    "\n",
    "file_regex = r\"bipartite_(?P<country>\\w+)_from(?P<date_from>\\d{4}-\\d\\d-\\d\\d).*to(?P<date_to>\\d{4}-\\d\\d-\\d\\d)\"\n",
    "comm_regex = r\"^Community (?P<community_id>\\d+)\\[(?P<vertex_type>V\\d+)\\]: (?P<vertexes>.*)$\"\n",
    "clus_regex = r\"^CoCluster (?P<cocluster_id>\\d+):(?P<vertex_type>V\\d+)\\((?P<a_id>\\d+)\\)-(?P<b_id>\\d+)$\"\n",
    "\n",
    "results: List[CommunityResultTime] = []\n",
    "for edgelist in matching_files:\n",
    "    edgelist = os.path.splitext(edgelist)[0]\n",
    "    print(edgelist)\n",
    "\n",
    "    matches = re.finditer(file_regex, edgelist, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        country = match.group(\"country\")\n",
    "        date_from = match.group(\"date_from\")\n",
    "        date_to = match.group(\"date_to\")\n",
    "\n",
    "    community_file = edgelist + \"_ResultsCommunities.txt\"\n",
    "    if not os.path.exists(community_file):\n",
    "        continue\n",
    "    with open(community_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    clusters: List[ClusterItem] = []\n",
    "    matches = re.finditer(comm_regex, text, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        community_id = match.group(\"community_id\")\n",
    "        vertex_type = match.group(\"vertex_type\")\n",
    "        vertexes = match.group(\"vertexes\").split(\", \")[0]\n",
    "        vertexes = vertexes.split(\",\")\n",
    "        # if vertex_type == \"V1\":\n",
    "        # print(community_id, vertex_type, vertexes)\n",
    "        cluster = ClusterItem(community_id=int(community_id), member=set(vertexes), type=VertexType(vertex_type))\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    with open(f\"{edgelist}_ResultsCoClusterCommunities.txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    coclusters: List[CoClusterItem] = []\n",
    "    matches = re.finditer(clus_regex, text, re.MULTILINE)\n",
    "\n",
    "    # NOTE: Becareful, the cocluster could be duplicated. like this:\n",
    "    # CoCluster 1:V1(1)-2\n",
    "    # CoCluster 2:V2(2)-1\n",
    "\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        cocluster_id = match.group(\"cocluster_id\")\n",
    "        vertex_type = match.group(\"vertex_type\")\n",
    "        a_id = match.group(\"a_id\")\n",
    "        b_id = match.group(\"b_id\")\n",
    "\n",
    "        # find the cluster with id a_id in clusters\n",
    "        for cluster in clusters:\n",
    "            if cluster.community_id == int(a_id):\n",
    "                a = cluster\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"cannot find cluster with id {a_id}\")\n",
    "\n",
    "        # do the same for b_id\n",
    "        for cluster in clusters:\n",
    "            if cluster.community_id == int(b_id):\n",
    "                b = cluster\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"cannot find cluster with id {b_id}\")\n",
    "\n",
    "        if VertexType(vertex_type) != \"V1\":\n",
    "            # swap a and b\n",
    "            a, b = b, a\n",
    "            a_id, b_id = b_id, a_id\n",
    "\n",
    "        # check if the cocluster (a_id, b_id) is already in the coclusters list\n",
    "        for _co in coclusters:\n",
    "            if _co.first.community_id == int(a_id) and _co.second.community_id == int(b_id):\n",
    "                break\n",
    "        else:\n",
    "            # if not, add it\n",
    "            cocluster = CoClusterItem(\n",
    "                cocluster_id=int(cocluster_id),\n",
    "                first=a,\n",
    "                second=b,\n",
    "            )\n",
    "            coclusters.append(cocluster)\n",
    "\n",
    "    comm_result = CommunityResult(\n",
    "        clusters=set(clusters),\n",
    "        coclusters=set(coclusters),\n",
    "    )\n",
    "\n",
    "    comm_time_result = CommunityResultTime(\n",
    "        community=comm_result,\n",
    "        country=country,\n",
    "        time_from=datetime.strptime(date_from, \"%Y-%m-%d\"),\n",
    "        time_to=datetime.strptime(date_to, \"%Y-%m-%d\"),\n",
    "    )\n",
    "    results.append(comm_time_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the results with time_from < 2013-01-01\n",
    "results = [x for x in results if x.time_from >= datetime(2013, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# calculate the similarity between pairs of coclusters in a and b\n",
    "pos = {}\n",
    "\n",
    "results = sorted(results, key=lambda x: x.time_from)\n",
    "for t, pair in enumerate(zip(results[:-1], results[1:])):\n",
    "    a, b = pair\n",
    "    for i, cocluster_a in enumerate(a.community.coclusters):\n",
    "        G.add_node(cocluster_a, time_from=a.time_from)\n",
    "        pos[cocluster_a] = np.array([t, i])\n",
    "        for j, cocluster_b in enumerate(b.community.coclusters):\n",
    "            G.add_node(cocluster_b, time_from=b.time_from)\n",
    "            pos[cocluster_b] = np.array([t + 1, j])\n",
    "            sim = cocluster_a.similarity(cocluster_b)\n",
    "            if sim > 0.0:\n",
    "                G.add_edge(cocluster_a, cocluster_b, weight=sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the attributes 'color' from all edges\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if \"color\" in data:\n",
    "        del data[\"color\"]\n",
    "\n",
    "# Iterate over the nodes in the graph\n",
    "for node in G.nodes:\n",
    "    # get the incomming edges of the current node\n",
    "    incoming_edges = G.in_edges(node, data=True)\n",
    "\n",
    "    # Find the edge with the highest weight\n",
    "    max_weight = 0\n",
    "    max_weight_edge = None\n",
    "    for edge in incoming_edges:\n",
    "        weight = edge[2][\"weight\"]\n",
    "        if weight > max_weight:\n",
    "            max_weight = weight\n",
    "            max_weight_edge = edge\n",
    "\n",
    "    # Highlight the edge with the highest weight\n",
    "    if max_weight_edge is not None:\n",
    "        G[max_weight_edge[0]][max_weight_edge[1]][\"color\"] = \"red\"\n",
    "\n",
    "# Set the edge colors based on the 'color' attribute\n",
    "edge_colors = [G[u][v].get(\"color\", \"gray\") for u, v in G.edges]\n",
    "edge_weights = [data[\"weight\"] for _, _, data in G.edges(data=True)]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Draw the graph with highlighted edges\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=False,\n",
    "    node_size=100,\n",
    "    node_color=\"lightblue\",\n",
    "    edge_color=edge_colors,\n",
    "    width=edge_weights,\n",
    "    arrowsize=5,\n",
    ")\n",
    "\n",
    "\n",
    "# Draw the edge labels with larger font size\n",
    "edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "edge_labels = {k: round(v, 2) for k, v in edge_labels.items()}\n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.38, alpha=0.7)\n",
    "\n",
    "\n",
    "# Add time_from on top of each column\n",
    "for t, result in enumerate(results):\n",
    "    plt.text(t, -1, result.time_from.strftime(\"%Y-%m-%d\"), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
