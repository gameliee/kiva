{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "from typing import List, Set, Any\n",
    "from dataclasses import dataclass\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexType(str, Enum):\n",
    "    \"\"\"Vertex type can only be `V1` or `V2`\"\"\"\n",
    "\n",
    "    V1 = \"V1\"\n",
    "    V2 = \"V2\"\n",
    "\n",
    "    def __new__(cls, value):\n",
    "        if value not in [\"V1\", \"V2\"]:\n",
    "            raise ValueError(\"vertex type can only be `V1` or `V2`\")\n",
    "        return super().__new__(cls, value)\n",
    "\n",
    "    def getother(self: \"VertexType\") -> \"VertexType\":\n",
    "        \"\"\"Return the other vertex type\"\"\"\n",
    "        if self == VertexType.V1:\n",
    "            return VertexType.V2\n",
    "        elif self == VertexType.V2:\n",
    "            return VertexType.V1\n",
    "\n",
    "\n",
    "assert VertexType(\"V1\") == VertexType.V1\n",
    "assert VertexType(\"V2\").getother() == VertexType.V1\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ClusterItem:\n",
    "    \"\"\"class of keeping track of cluster information\"\"\"\n",
    "\n",
    "    community_id: int\n",
    "    member: Set[Any]\n",
    "    type: VertexType | None = None  # type of the cluster\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash(str(self.community_id) + self.type)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        if self.type == VertexType.V1:\n",
    "            return str(self.member)\n",
    "        else:\n",
    "            return str(list(self.member)[0:5] + [\"...\"])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CoClusterItem:\n",
    "    \"\"\"class of keeping track of co-cluster information\"\"\"\n",
    "\n",
    "    cocluster_id: int\n",
    "    first: ClusterItem\n",
    "    second: ClusterItem\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.cocluster_id, self.first, self.second, self.first, self.second))\n",
    "\n",
    "    def similarity(self, other: \"CoClusterItem\") -> float:\n",
    "        \"\"\"Calculate the similarity between two coclusters\"\"\"\n",
    "        # overlap over union of the first vertex type\n",
    "        first_overlap = len(self.first.member.intersection(other.first.member))\n",
    "        first_union = len(self.first.member.union(other.first.member))\n",
    "        first_similarity = first_overlap / first_union\n",
    "        # overlap over union of the second vertex type\n",
    "        second_overlap = len(self.second.member.intersection(other.second.member))\n",
    "        second_union = len(self.second.member.union(other.second.member))\n",
    "        second_similarity = second_overlap / second_union\n",
    "        # return the average of the two similarities\n",
    "        return (first_similarity + second_similarity) / 2\n",
    "\n",
    "\n",
    "def test_CoclusterItem():\n",
    "    \"\"\"test the similarity function\"\"\"\n",
    "    cluster11 = ClusterItem(1, {\"A\", \"B\", \"C\"})\n",
    "    cluster12 = ClusterItem(2, {\"D\", \"E\", \"F\"})\n",
    "    cluster21 = ClusterItem(3, {1, 2, 3})\n",
    "    cluster22 = ClusterItem(4, {4, 5, 6})\n",
    "    cocluster1 = CoClusterItem(1, cluster11, cluster21)\n",
    "    cocluster2 = CoClusterItem(2, cluster12, cluster22)\n",
    "    assert cocluster1.similarity(cocluster2) == 0.0\n",
    "    cocluster3 = CoClusterItem(3, cluster11, cluster22)\n",
    "    assert cocluster1.similarity(cocluster3) == 0.5\n",
    "\n",
    "\n",
    "test_CoclusterItem()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CommunityResult:\n",
    "    \"\"\"class of keeping track of community detection result\"\"\"\n",
    "\n",
    "    clusters: Set[ClusterItem]\n",
    "    coclusters: Set[CoClusterItem]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CommunityResultTime:\n",
    "    \"\"\"class of keeping track of community detection result with time\"\"\"\n",
    "\n",
    "    community: CommunityResult\n",
    "    country: str\n",
    "    time_from: datetime\n",
    "    time_to: datetime\n",
    "    biLouvian_order: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_files = glob.glob(\"checkpoints/LT_bipartite_*.csv\")\n",
    "matching_files = sorted(matching_files)\n",
    "\n",
    "file_regex = r\"bipartite_(?P<country>\\w+)_from(?P<date_from>\\d{4}-\\d\\d-\\d\\d).*to(?P<date_to>\\d{4}-\\d\\d-\\d\\d)\"\n",
    "comm_regex = r\"^Community (?P<community_id>\\d+)\\[(?P<vertex_type>V\\d+)\\]: (?P<vertexes>.*)$\"\n",
    "clus_regex = r\"^CoCluster (?P<cocluster_id>\\d+):(?P<vertex_type>V\\d+)\\((?P<a_id>\\d+)\\)-(?P<b_id>\\d+)$\"\n",
    "\n",
    "results: List[CommunityResultTime] = []\n",
    "for edgelist in matching_files:\n",
    "    edgelist = os.path.splitext(edgelist)[0]\n",
    "    print(edgelist)\n",
    "\n",
    "    matches = re.finditer(file_regex, edgelist, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        country = match.group(\"country\")\n",
    "        date_from = match.group(\"date_from\")\n",
    "        date_to = match.group(\"date_to\")\n",
    "\n",
    "    community_file = edgelist + \"_ResultsCommunities.txt\"\n",
    "    if not os.path.exists(community_file):\n",
    "        continue\n",
    "    with open(community_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    clusters: List[ClusterItem] = []\n",
    "    matches = re.finditer(comm_regex, text, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        community_id = match.group(\"community_id\")\n",
    "        vertex_type = match.group(\"vertex_type\")\n",
    "        vertexes = match.group(\"vertexes\").split(\", \")[0]\n",
    "        vertexes = vertexes.split(\",\")\n",
    "        # if vertex_type == \"V1\":\n",
    "        # print(community_id, vertex_type, vertexes)\n",
    "        cluster = ClusterItem(community_id=int(community_id), member=set(vertexes), type=VertexType(vertex_type))\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    with open(f\"{edgelist}_ResultsCoClusterCommunities.txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    coclusters: List[CoClusterItem] = []\n",
    "    matches = re.finditer(clus_regex, text, re.MULTILINE)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        cocluster_id = match.group(\"cocluster_id\")\n",
    "        vertex_type = match.group(\"vertex_type\")\n",
    "        a_id = match.group(\"a_id\")\n",
    "        b_id = match.group(\"b_id\")\n",
    "\n",
    "        # find the cluster with id a_id in clusters\n",
    "        for cluster in clusters:\n",
    "            if cluster.community_id == int(a_id):\n",
    "                a = cluster\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"cannot find cluster with id {a_id}\")\n",
    "\n",
    "        # do the same for b_id\n",
    "        for cluster in clusters:\n",
    "            if cluster.community_id == int(b_id):\n",
    "                b = cluster\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"cannot find cluster with id {b_id}\")\n",
    "\n",
    "        if VertexType(vertex_type) != \"V1\":\n",
    "            # swap a and b\n",
    "            a, b = b, a\n",
    "\n",
    "        cocluster = CoClusterItem(\n",
    "            cocluster_id=int(cocluster_id),\n",
    "            first=a,\n",
    "            second=b,\n",
    "        )\n",
    "        coclusters.append(cocluster)\n",
    "\n",
    "    comm_result = CommunityResult(\n",
    "        clusters=set(clusters),\n",
    "        coclusters=set(coclusters),\n",
    "    )\n",
    "\n",
    "    comm_time_result = CommunityResultTime(\n",
    "        community=comm_result,\n",
    "        country=country,\n",
    "        time_from=datetime.strptime(date_from, \"%Y-%m-%d\"),\n",
    "        time_to=datetime.strptime(date_to, \"%Y-%m-%d\"),\n",
    "    )\n",
    "    results.append(comm_time_result)\n",
    "\n",
    "    coclusters_df = pd.DataFrame(coclusters)\n",
    "    coclusters_df[\"first_id\"] = coclusters_df[\"first\"].apply(lambda x: x[\"community_id\"])\n",
    "    coclusters_df[\"second_id\"] = coclusters_df[\"second\"].apply(lambda x: x[\"community_id\"])\n",
    "    coclusters_df = coclusters_df.drop(columns=[\"first\", \"second\"])\n",
    "    assert coclusters_df.drop(columns=\"cocluster_id\").duplicated().sum() == len(coclusters_df) / 2\n",
    "    # print(coclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the results with time_from < 2013-01-01\n",
    "results = [x for x in results if x.time_from >= datetime(2013, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# calculate the similarity between pairs of coclusters in a and b\n",
    "pos = {}\n",
    "\n",
    "results = sorted(results, key=lambda x: x.time_from)[-3:-1]\n",
    "for t, pair in enumerate(zip(results[:-1], results[1:])):\n",
    "    a, b = pair\n",
    "    for i, cocluster_a in enumerate(a.community.coclusters):\n",
    "        G.add_node(cocluster_a, time_from=a.time_from)\n",
    "        pos[cocluster_a] = np.array([t, i])\n",
    "        for j, cocluster_b in enumerate(b.community.coclusters):\n",
    "            G.add_node(cocluster_b, time_from=b.time_from)\n",
    "            pos[cocluster_b] = np.array([t + 1, j])\n",
    "            sim = cocluster_a.similarity(cocluster_b)\n",
    "            if sim > 0.0:\n",
    "                G.add_edge(cocluster_a, cocluster_b, weight=sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G, pos, with_labels=False, node_size=100, node_color=\"lightblue\", edge_color=\"gray\", width=0.5, arrowsize=5)\n",
    "\n",
    "# Draw the edge labels with larger font size\n",
    "edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "edge_labels = {k: round(v, 2) for k, v in edge_labels.items()}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "# Add time_from on top of each column\n",
    "for t, result in enumerate(results):\n",
    "    plt.text(t, len(results), result.time_from.strftime(\"%Y-%m-%d\"), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the attributes 'color' from all edges\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if \"color\" in data:\n",
    "        del data[\"color\"]\n",
    "\n",
    "# Iterate over the nodes in the graph\n",
    "for node in G.nodes:\n",
    "    # get the incomming edges of the current node\n",
    "    incoming_edges = G.in_edges(node, data=True)\n",
    "\n",
    "    # Find the edge with the highest weight\n",
    "    max_weight = 0\n",
    "    max_weight_edge = None\n",
    "    for edge in incoming_edges:\n",
    "        weight = edge[2][\"weight\"]\n",
    "        if weight > max_weight:\n",
    "            max_weight = weight\n",
    "            max_weight_edge = edge\n",
    "\n",
    "    # Highlight the edge with the highest weight\n",
    "    if max_weight_edge is not None:\n",
    "        G[max_weight_edge[0]][max_weight_edge[1]][\"color\"] = \"red\"\n",
    "\n",
    "# Set the edge colors based on the 'color' attribute\n",
    "edge_colors = [G[u][v].get(\"color\", \"gray\") for u, v in G.edges]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Draw the graph with highlighted edges\n",
    "nx.draw(\n",
    "    G, pos, with_labels=False, node_size=100, node_color=\"lightblue\", edge_color=edge_colors, width=0.5, arrowsize=5\n",
    ")\n",
    "\n",
    "# Draw the edge labels with larger font size\n",
    "edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "edge_labels = {k: round(v, 2) for k, v in edge_labels.items()}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "# Add time_from on top of each column\n",
    "for t, result in enumerate(results):\n",
    "    plt.text(t, len(results), result.time_from.strftime(\"%Y-%m-%d\"), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should find maximum differently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
