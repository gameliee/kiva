{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameter cell\n",
    "FROM = \"2022-01-01\"\n",
    "TO = \"2023-01-01\"\n",
    "COUNTRY = \"United States\"\n",
    "ORDER = 1  # will be pass to param order in biLouvian call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import preprocessed data with active lenders only, and filter by the Paramteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_parquet(\"../data/gen/preprocessed_2023-08-28T11-09-39_from_2019-01-01_activelender.parquet\")\n",
    "ds[\"sector_name\"] = ds[\"sector_name\"].astype(\"category\")\n",
    "ds[\"geocode_country_name\"] = ds[\"geocode_country_name\"].astype(\"category\")\n",
    "ds[\"activity_name\"] = ds[\"activity_name\"].astype(\"category\")\n",
    "ds.drop(columns=[\"tags\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sector_name.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dropna(axis=0, how=\"all\", inplace=True)\n",
    "print(len(ds))\n",
    "ds.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[(ds.fundraisingDate >= FROM) & (ds.fundraisingDate < TO)]\n",
    "\"the number of Loans under investigation is\", len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[ds.geocode_country_name == COUNTRY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.duplicated(subset=[\"project_id\", \"lender_id\", \"loan_shareAmount\", \"loan_date\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Projects\", ds.project_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Lenders\", ds.lender_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Loans\", ds.loan_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"number of Sectors\", ds.sector_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct `Lender-Sector` bipartite graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edge list of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS = ds.groupby([\"lender_id\", \"sector_id\"], observed=True).agg(\n",
    "    {\"sector_name\": \"first\", \"loan_shareAmount\": \"sum\", \"loan_date\": \"count\", \"lender_publicId\": \"first\"}\n",
    ")\n",
    "LS.reset_index(inplace=True)\n",
    "LS.rename(columns={\"loan_shareAmount\": \"loan_amount\", \"loan_date\": \"loan_count\"}, inplace=True)\n",
    "LS = LS[LS[\"loan_amount\"] > 0]\n",
    "LS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to the format that `biLouvian` can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must convert sector_name from category to object first\n",
    "# because if it is category, the LabelEncoder will return the index of the category\n",
    "# which is not desired. We want the encoded value to be in the range of [0, n-1]\n",
    "LS[\"sector_name\"] = LS[\"sector_name\"].astype(\"object\")\n",
    "le1 = LabelEncoder()\n",
    "LS[\"V1\"] = le1.fit_transform(LS[\"sector_name\"])\n",
    "le2 = LabelEncoder()\n",
    "LS[\"V2\"] = le2.fit_transform(LS[\"lender_id\"]) + LS[\"V1\"].max() + 1\n",
    "LS.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of vertex\n",
    "vertex_count = LS[\"lender_id\"].nunique() + LS[\"sector_name\"].nunique()\n",
    "assert vertex_count == LS[\"V1\"].nunique() + LS[\"V2\"].nunique()\n",
    "print(vertex_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary1 = LS[[\"V1\", \"sector_name\"]].drop_duplicates()\n",
    "dictionary1.rename(columns={\"sector_name\": \"name\", \"V1\": \"id\"}, inplace=True)\n",
    "dictionary1[\"name\"] = dictionary1[\"name\"].astype(str)\n",
    "dictionary1.sort_values(by=[\"id\"]).tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary2 = LS[[\"V2\", \"lender_publicId\"]].drop_duplicates()\n",
    "dictionary2.rename(columns={\"lender_publicId\": \"name\", \"V2\": \"id\"}, inplace=True)\n",
    "dictionary2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat two dictionaries\n",
    "dictionary = pd.concat([dictionary1, dictionary2])\n",
    "print(len(dictionary))\n",
    "assert len(dictionary) == vertex_count\n",
    "# confirm that dictionary's id is a range\n",
    "assert dictionary[\"id\"].min() == 0\n",
    "assert dictionary[\"id\"].max() == vertex_count - 1\n",
    "assert dictionary.duplicated().sum() == 0\n",
    "dictionary.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = f\"checkpoints/LS_US_active_from{FROM}_to{TO}_order{ORDER}_bipartite\"  # the text \"bipartite\" is mandatory\n",
    "filename = f\"{prefix}.csv\"\n",
    "dictfile = f\"{prefix}_Dictionary.txt\"  # \"_Dictionary.txt\" is mandatory\n",
    "LS[[\"V1\", \"V2\", \"loan_amount\"]].to_csv(filename, sep=\"\\t\", header=False, index=False)  # \"\\t\" is mandatory\n",
    "dictionary[[\"id\", \"name\"]].to_csv(dictfile, sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run `biLouvian`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Have to build the `biLouvian` binary first. Refer to `doc/BUILD_BILOUVIAN.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"../extra/biLouvian -i {filename} -order {ORDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../extra/biLouvain -i $filename -order $ORDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biLouvian_helper import *\n",
    "\n",
    "result_mutaraplus(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result_community(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result.clusters), len(result.coclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# find all cluster type v1, then concat their member\n",
    "# remember that result.clusters is a Set\n",
    "\n",
    "v1 = [list(c.member) for c in list(result.clusters) if c.type == VertexType.V1]\n",
    "sorted_v1 = np.concatenate(v1)\n",
    "sorted_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = [list(c.member) for c in list(result.clusters) if c.type == VertexType.V2]\n",
    "sorted_v2 = np.concatenate(v2)\n",
    "len(sorted_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{prefix}.csv\"\n",
    "edge_list = pd.read_csv(filename, names=[\"V1\", \"V2\", \"weight\"], sep=\"\\t\", header=None)\n",
    "edge_list.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictfile = f\"{prefix}_Dictionary.txt\"\n",
    "dictionary = pd.read_csv(dictfile, names=[\"id\", \"name\"], sep=\"\\t\", header=None)\n",
    "dictionary.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the V1 and V2 in edges_list with their corresponding name in dictionary\n",
    "edge_list = edge_list.merge(dictionary, left_on=\"V1\", right_on=\"id\")\n",
    "edge_list.rename(columns={\"name\": \"V1_name\"}, inplace=True)\n",
    "edge_list = edge_list.merge(dictionary, left_on=\"V2\", right_on=\"id\")\n",
    "edge_list.rename(columns={\"name\": \"V2_name\"}, inplace=True)\n",
    "edge_list.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the weights from edge_list\n",
    "weights = edge_list[\"weight\"]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(weights, bins=10, log=True)\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Frequency (log scale)\")\n",
    "plt.title(\"Histogram of Edge Weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph from sorted_v1 and sorted_v2\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(sorted_v1, bipartite=0)  # have to be in order\n",
    "B.add_nodes_from(sorted_v2, bipartite=1)  # have to be in order\n",
    "# B.add_weighted_edges_from(edge_list[[\"V1_name\", \"V2_name\", \"weight\"]].values.tolist())\n",
    "B.add_edges_from(edge_list[[\"V1_name\", \"V2_name\"]].values.tolist())\n",
    "assert B.number_of_nodes() == len(sorted_v1) + len(sorted_v2)\n",
    "assert B.number_of_edges() == len(edge_list)\n",
    "B.number_of_nodes(), B.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list[[\"V1_name\", \"V2_name\"]].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "# Get the biadjacency matrix of graph B\n",
    "biadjacency_matrix = bipartite.biadjacency_matrix(B, row_order=sorted_v2, column_order=sorted_v1)\n",
    "\n",
    "# Convert the matrix to a numpy array\n",
    "biadjacency_array = biadjacency_matrix.toarray()\n",
    "\n",
    "# Plot the biadjacency matrix as an image\n",
    "plt.imshow(biadjacency_array, origin=\"lower\")\n",
    "plt.xlabel(\"V2\")\n",
    "plt.ylabel(\"V1\")\n",
    "plt.title(\"Biadjacency Matrix\")\n",
    "plt.gca().set_aspect(aspect=0.001)\n",
    "# plt.colorbar()\n",
    "\n",
    "# Disable ticks in all axes\n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, left=False, right=False)\n",
    "\n",
    "# Also disable values in axis\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# enable grid\n",
    "plt.grid(True, which=\"both\", axis=\"both\", linestyle=\"-\", color=\"w\", linewidth=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
